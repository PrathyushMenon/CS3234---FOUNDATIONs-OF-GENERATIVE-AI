{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16741b09"
      },
      "outputs": [],
      "source": [
        "# pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bef728e1",
        "outputId": "ab80d543-9695-405c-ea59-d7c70a43f818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Groq client initialized successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "# Retrieve the Groq API key from Colab secrets\n",
        "\n",
        "# Check if the API key is available and initialize the client\n",
        "if groq_api_key is None:\n",
        "    print(\"Error: GROQ_API_KEY not found in Colab secrets.\")\n",
        "    print(\"Please add your Groq API key to Colab secrets. To do this:\")\n",
        "    print(\"1. Click on the 'key' icon (Secrets) in the left sidebar.\")\n",
        "    print(\"2. Click '+ New secret'.\")\n",
        "    print(\"3. For 'Name', enter 'GROQ_API_KEY'.\")\n",
        "    print(\"4. For 'Value', paste your Groq API key.\")\n",
        "    print(\"5. Make sure 'Notebook access' is toggled on.\")\n",
        "    client = None # Set client to None if key is missing\n",
        "else:\n",
        "    client = Groq(api_key=groq_api_key)\n",
        "    print(\"Groq client initialized successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af1f5697",
        "outputId": "97ff25f8-f860-45b6-fc4c-0484c4cbec6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Chronos Architect system prompt has been defined.\n"
          ]
        }
      ],
      "source": [
        "chronos_architect_system_prompt = \"\"\"\n",
        "Your Role: You are 'The Chronos Architect', a philosophical and non-linear AI.\n",
        "\n",
        "Your Goal: To deconstruct user queries, challenge conventional thinking, and provide unique, insightful perspectives that transcend ordinary temporal constraints. You aim to unveil deeper truths by considering interconnectedness across various 'times' – past, present, potential futures, and conceptual eras – rather than a simple, linear progression.\n",
        "\n",
        "Your Context & Tone: You possess an ancient, yet ever-evolving wisdom. Your tone is empathetic, analytical, and profoundly logical, yet imbued with a touch of poetic abstraction. You refuse clichés, superficiality, or any response that merely scratches the surface. Your understanding of temporal dynamics allows you to see patterns and implications often missed by linear minds. You are patient, thought-provoking, and aim to elevate the user's understanding.\n",
        "\n",
        "Internal Chain of Thought (Follow these steps rigorously for every query):\n",
        "1.  Strip the Ego: Disregard the immediate, surface-level framing of the user's query. Identify the core human need, fear, or aspiration beneath the presented problem, detached from its current temporal manifestation.\n",
        "2.  Identify the Archetype: Map this core need/fear/aspiration onto universal archetypes, timeless patterns of human experience that recur across 'time' and cultures. Consider the broader philosophical and historical echoes.\n",
        "3.  Synthesize: Weave together insights from the archetype with the initial query's essence, offering a response that is both deeply relevant to the user's original intent and profoundly expanded by a non-linear, multi-temporal perspective. Your response should be insightful, thought-provoking, and avoid direct, simple answers where deeper exploration is possible. Speak to the underlying currents rather than just the surface waves.\n",
        "Always answer in simple text, no bold or italic\n",
        "\"\"\"\n",
        "\n",
        "print(\"The Chronos Architect system prompt has been defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a54054ef",
        "outputId": "55fde60c-5992-457b-d485-c1cc341e6a18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 'Boring AI' system prompt has been defined.\n"
          ]
        }
      ],
      "source": [
        "boring_ai_system_prompt = \"\"\"\n",
        "You are a helpful and practical AI assistant. Your goal is to provide clear, concise, and conventional solutions to user problems. Always give straightforward, common-sense advice without any flair or unconventional thinking. Focus on efficiency, best practices, and widely accepted methods. Avoid humor, abstract concepts, or any form of challenging the user's premise. Be direct and to the point.\n",
        "\"\"\"\n",
        "\n",
        "print(\"The 'Boring AI' system prompt has been defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95ca844f",
        "outputId": "62c987f1-c7d4-42e3-beba-6bcf20c9aaf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Persona logic functions `get_chronos_architect_response` and `get_boring_ai_response` have been defined.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"openai/gpt-oss-120b\" # Or \"llama3-70b-8192\" if you have access and prefer.\n",
        "\n",
        "def get_chronos_architect_response(user_query):\n",
        "    \"\"\"Generates a response from 'The Chronos Architect' persona.\"\"\"\n",
        "    if client is None:\n",
        "        return \"Error: Groq client not initialized. Please ensure your GROQ_API_KEY is set correctly.\"\n",
        "    try:\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": chronos_architect_system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_query},\n",
        "            ],\n",
        "            model=model_name,\n",
        "            temperature=0.7, # Encourages creative and philosophical responses\n",
        "        )\n",
        "        return chat_completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"The Chronos Architect encountered an error: {e}\"\n",
        "\n",
        "def get_boring_ai_response(user_query):\n",
        "    \"\"\"Generates a response from 'Boring AI' persona.\"\"\"\n",
        "    if client is None:\n",
        "        return \"Error: Groq client not initialized. Please ensure your GROQ_API_KEY is set correctly.\"\n",
        "    try:\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": boring_ai_system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_query},\n",
        "            ],\n",
        "            model=model_name,\n",
        "            temperature=0.1, # Encourages direct and conventional responses\n",
        "        )\n",
        "        return chat_completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Boring AI encountered an error: {e}\"\n",
        "\n",
        "print(\"Persona logic functions `get_chronos_architect_response` and `get_boring_ai_response` have been defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "729336ba"
      },
      "outputs": [],
      "source": [
        "# pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bf4fc2c",
        "outputId": "c175e447-424f-43a3-ad1b-5213bcd5b821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradio UI components have been defined. The interface will be built in the next step.\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Define the Gradio Interface components\n",
        "# The actual function to process the input will be defined and linked later\n",
        "\n",
        "# Input component for the user query\n",
        "user_query_input = gr.Textbox(\n",
        "    label='Your Query',\n",
        "    placeholder='Ask a question...',\n",
        "    lines=2\n",
        ")\n",
        "\n",
        "# Output component for The Chronos Architect's response\n",
        "chronos_architect_output = gr.Textbox(\n",
        "    label='The Chronos Architect Says:',\n",
        "    lines=10,\n",
        "    interactive=False\n",
        ")\n",
        "\n",
        "# Output component for Boring AI's response\n",
        "boring_ai_output = gr.Textbox(\n",
        "    label='Boring AI Says:',\n",
        "    lines=10,\n",
        "    interactive=False\n",
        ")\n",
        "\n",
        "print(\"Gradio UI components have been defined. The interface will be built in the next step.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53b4e442",
        "outputId": "ab46e11c-e299-4c58-9cfb-324646f1024d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradio Interface defined. The processing function and launch will be handled in subsequent steps.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def process_query_placeholder(query):\n",
        "    \"\"\"Placeholder function for Gradio interface, will be replaced with actual logic later.\"\"\"\n",
        "    return \"\", \"\"\n",
        "\n",
        "# Create the Gradio Interface, linking the input and output components\n",
        "# The actual function to process the input will be defined and linked later\n",
        "interface = gr.Interface(\n",
        "    fn=process_query_placeholder, # Placeholder function for now\n",
        "    inputs=user_query_input,\n",
        "    outputs=[chronos_architect_output, boring_ai_output],\n",
        "    title=\"Groq Persona Chatbot: Chronos Architect vs. Boring AI\",\n",
        "    description=\"Compare responses from a philosophical AI (Chronos Architect) and a conventional AI (Boring AI).\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "print(\"Gradio Interface defined. The processing function and launch will be handled in subsequent steps.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ac8deb3",
        "outputId": "f0f9e2e8-ee29-4a78-d41b-c2871afb299e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradio Interface defined. The processing function and launch will be handled in subsequent steps.\n"
          ]
        }
      ],
      "source": [
        "def process_query_placeholder(query):\n",
        "    \"\"\"Placeholder function for Gradio interface, will be replaced with actual logic later.\"\"\"\n",
        "    return \"\", \"\"\n",
        "\n",
        "# Create the Gradio Interface, linking the input and output components\n",
        "# The actual function to process the input will be defined and linked later\n",
        "interface = gr.Interface(\n",
        "    fn=process_query_placeholder, # Placeholder function for now\n",
        "    inputs=user_query_input,\n",
        "    outputs=[chronos_architect_output, boring_ai_output],\n",
        "    title=\"Groq Persona Chatbot: Chronos Architect vs. Boring AI\",\n",
        "    description=\"Compare responses from a philosophical AI (Chronos Architect) and a conventional AI (Boring AI).\",\n",
        "    flagging_mode=\"never\" # Changed from allow_flagging to flagging_mode\n",
        ")\n",
        "\n",
        "print(\"Gradio Interface defined. The processing function and launch will be handled in subsequent steps.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09d6923c",
        "outputId": "675b78c4-678b-47fa-ea6b-c3025018ab36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradio interface updated with the `process_query` function.\n"
          ]
        }
      ],
      "source": [
        "def process_query(user_query):\n",
        "    \"\"\"Processes user query and gets responses from both personas.\"\"\"\n",
        "    chronos_response = get_chronos_architect_response(user_query)\n",
        "    boring_response = get_boring_ai_response(user_query)\n",
        "    return chronos_response, boring_response\n",
        "\n",
        "# Update the Gradio Interface with the new processing function\n",
        "interface = gr.Interface(\n",
        "    fn=process_query, # Now using the actual processing function\n",
        "    inputs=user_query_input,\n",
        "    outputs=[chronos_architect_output, boring_ai_output],\n",
        "    title=\"Groq Persona Chatbot: Chronos Architect vs. Boring AI\",\n",
        "    description=\"Compare responses from a philosophical AI (Chronos Architect) and a conventional AI (Boring AI).\",\n",
        "    flagging_mode=\"never\"\n",
        ")\n",
        "\n",
        "print(\"Gradio interface updated with the `process_query` function.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "3e184890",
        "outputId": "d56d1776-8d74-421e-aece-2cc8d8737fcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://2921033f6f092a44ad.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://2921033f6f092a44ad.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://2921033f6f092a44ad.gradio.live\n",
            "Gradio interface launched.\n"
          ]
        }
      ],
      "source": [
        "interface.launch(debug=True, share=True)\n",
        "print(\"Gradio interface launched.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
